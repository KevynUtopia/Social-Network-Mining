{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24154,
     "status": "ok",
     "timestamp": 1620014631648,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "f5aCnSbsDsGH",
    "outputId": "6dca5cc7-75a5-4496-f233-603d55059aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1620014636497,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "AK6FyjufD5PP"
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    read edges from an edge file\n",
    "    \"\"\"\n",
    "    edges = list()\n",
    "    df = pd.read_csv(file_name)\n",
    "    for idx, row in df.iterrows():\n",
    "        user_id, friends = row[\"user_id\"], eval(row[\"friends\"])\n",
    "        for friend in friends:\n",
    "            # add each friend relation as an edge\n",
    "            edges.append((user_id, friend))\n",
    "    edges = sorted(edges)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n",
    "def load_test_data(file_name):\n",
    "    \"\"\"\n",
    "    read edges from an edge file\n",
    "    \"\"\"\n",
    "    edges = list()\n",
    "    scores = list()\n",
    "    df = pd.read_csv(file_name)\n",
    "    for idx, row in df.iterrows():\n",
    "        edges.append((row[\"src\"], row[\"dst\"]))\n",
    "    edges = sorted(edges)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n",
    "def generate_false_edges(true_edges, num_false_edges=5):\n",
    "    \"\"\"\n",
    "    generate false edges given true edges\n",
    "    \"\"\"\n",
    "    nodes = list(set(chain.from_iterable(true_edges)))\n",
    "    N = len(nodes)\n",
    "    true_edges = set(true_edges)\n",
    "    print(N, len(true_edges))\n",
    "    false_edges = set()\n",
    "    \n",
    "    while len(false_edges) < num_false_edges:\n",
    "        # randomly sample two different nodes and check whether the pair exisit or not\n",
    "        src, dst = nodes[int(np.random.rand() * N)], nodes[int(np.random.rand() * N)]\n",
    "        if src != dst and (src, dst) not in true_edges and (src, dst) not in false_edges:\n",
    "            false_edges.add((src, dst))\n",
    "    false_edges = sorted(false_edges)\n",
    "    \n",
    "    return false_edges\n",
    "\n",
    "\n",
    "def construct_graph_from_edges(edges):\n",
    "    \"\"\"\n",
    "    generate a directed graph object given true edges\n",
    "    DiGraph documentation: https://networkx.github.io/documentation/stable/reference/classes/digraph.html\n",
    "    \"\"\"\n",
    "    # convert a list of edges {(u, v)} to a list of edges with weights {(u, v, w)}\n",
    "    edge_weight = defaultdict(float)\n",
    "    for e in edges:\n",
    "        edge_weight[e] += 1.0\n",
    "    weighed_edge_list = list()\n",
    "    for e in sorted(edge_weight.keys()):\n",
    "        weighed_edge_list.append((e[0], e[1], edge_weight[e]))\n",
    "        \n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(weighed_edge_list)\n",
    "    \n",
    "    print(\"number of nodes:\", graph.number_of_nodes())\n",
    "    print(\"number of edges:\", graph.number_of_edges())\n",
    "    \n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2646,
     "status": "ok",
     "timestamp": 1620014639836,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "n5hkbMKUD5SG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def alias_setup(probs):\n",
    "    \"\"\"\n",
    "    compute utility lists for non-uniform sampling from discrete distributions.\n",
    "    details: https://lips.cs.princeton.edu/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
    "    \"\"\"\n",
    "    K = len(probs)\n",
    "    q = np.zeros(K)\n",
    "    J = np.zeros(K, dtype=np.int)\n",
    "\n",
    "    smaller = list()\n",
    "    larger = list()\n",
    "    for kk, prob in enumerate(probs):\n",
    "        q[kk] = K * prob\n",
    "        if q[kk] < 1.0:\n",
    "            smaller.append(kk)\n",
    "        else:\n",
    "            larger.append(kk)\n",
    "\n",
    "    while len(smaller) > 0 and len(larger) > 0:\n",
    "        small = smaller.pop()\n",
    "        large = larger.pop()\n",
    "\n",
    "        J[small] = large\n",
    "        q[large] = q[large] + q[small] - 1.0\n",
    "        if q[large] < 1.0:\n",
    "            smaller.append(large)\n",
    "        else:\n",
    "            larger.append(large)\n",
    "\n",
    "    return J, q\n",
    "\n",
    "\n",
    "def get_alias_node(graph, node):\n",
    "    \"\"\"\n",
    "    get the alias node setup lists for a given node.\n",
    "    \"\"\"\n",
    "    # get the unnormalized probabilities with the first-order information\n",
    "    unnormalized_probs = list()\n",
    "    for nbr in graph.neighbors(node):\n",
    "        unnormalized_probs.append(graph[node][nbr][\"weight\"])\n",
    "    unnormalized_probs = np.array(unnormalized_probs)\n",
    "    if len(unnormalized_probs) > 0:\n",
    "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
    "    else:\n",
    "        normalized_probs = unnormalized_probs\n",
    "        \n",
    "    return alias_setup(normalized_probs)\n",
    "\n",
    "   \n",
    "def get_alias_edge(graph, src, dst, p=1, q=1):\n",
    "    \"\"\"\n",
    "    get the alias edge setup lists for a given edge.\n",
    "    \"\"\"\n",
    "    # get the unnormalized probabilities with the second-order information\n",
    "    unnormalized_probs = list()\n",
    "    for dst_nbr in graph.neighbors(dst):\n",
    "        if dst_nbr == src: # distance is 0\n",
    "            unnormalized_probs.append(graph[dst][dst_nbr][\"weight\"]/p)\n",
    "        elif graph.has_edge(dst_nbr, src): # distance is 1\n",
    "            unnormalized_probs.append(graph[dst][dst_nbr][\"weight\"])\n",
    "        else: # distance is 2\n",
    "            unnormalized_probs.append(graph[dst][dst_nbr][\"weight\"]/q)\n",
    "    unnormalized_probs = np.array(unnormalized_probs)\n",
    "    if len(unnormalized_probs) > 0:\n",
    "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
    "    else:\n",
    "        normalized_probs = unnormalized_probs\n",
    "\n",
    "    return alias_setup(normalized_probs)\n",
    "\n",
    "\n",
    "def preprocess_transition_probs(graph, p=1, q=1):\n",
    "    \"\"\"\n",
    "    preprocess transition probabilities for guiding the random walks.\n",
    "    \"\"\"\n",
    "    alias_nodes = dict()\n",
    "    for node in graph.nodes():\n",
    "        alias_nodes[node] = get_alias_node(graph, node)\n",
    "\n",
    "    alias_edges = dict()\n",
    "    for edge in graph.edges():\n",
    "        alias_edges[edge] = get_alias_edge(graph, edge[0], edge[1], p=p, q=q)\n",
    "\n",
    "    return alias_nodes, alias_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1620014642666,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "sCijHbdvD5VB"
   },
   "outputs": [],
   "source": [
    "\n",
    "def alias_draw(J, q):\n",
    "    \"\"\"\n",
    "    draw sample from a non-uniform discrete distribution using alias sampling.\n",
    "    \"\"\"\n",
    "    K = len(J)\n",
    "\n",
    "    kk = int(np.floor(np.random.rand() * K))\n",
    "    if np.random.rand() < q[kk]:\n",
    "        return kk\n",
    "    else:\n",
    "        return J[kk]\n",
    "\n",
    "\n",
    "# helper function to generate the long random walk as desired\n",
    "\n",
    "def fallback(walk, fetch_last_num=1):\n",
    "    if len(walk) > fetch_last_num:\n",
    "        walk.pop()\n",
    "        fetched = []\n",
    "        for i in range(fetch_last_num):\n",
    "            fetched.append(walk[-1-i])\n",
    "        return walk, fetched\n",
    "    else:\n",
    "        return [], [None for _ in range(fetch_last_num)]\n",
    "\n",
    "\n",
    "def generate_first_order_random_walk(graph, alias_nodes, \n",
    "                                     walk_length=10, start_node=None, verbose=False, max_trails=10):\n",
    "    \"\"\"\n",
    "    simulate a random walk starting from start node and considering the first order information.\n",
    "    max_trials: set the max trials to be one for standard random walk. Larger max_trails will make the generated biased.\n",
    "    \"\"\"\n",
    "    if start_node == None:\n",
    "        start_node = np.random.choice(graph.nodes())\n",
    "    walk = [start_node]\n",
    "    cur = start_node\n",
    "    num_tried = 0\n",
    "    \n",
    "    ########## begin ##########\n",
    "    while len(walk) < walk_length:\n",
    "        cur_nbrs = list(graph.neighbors(cur))\n",
    "        if len(cur_nbrs) > 0: # if we can sample next nodes\n",
    "            # sample the next node based on alias_nodes\n",
    "            cur = cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
    "            walk.append(cur)\n",
    "        else: # if we can't do that\n",
    "            num_tried += 1\n",
    "            if num_tried >= max_trails:\n",
    "                break\n",
    "\n",
    "            walk, fetched = fallback(walk, fetch_last_num=1)\n",
    "            cur = fetched[0]\n",
    "            if len(walk) == 0: # if falls back to the empty walk\n",
    "                start_node = np.random.choice(graph.nodes())\n",
    "                walk = [start_node]\n",
    "                cur = start_node\n",
    "    ########## end ##########\n",
    "\n",
    "    if verbose: \n",
    "        print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
    "    return walk\n",
    "\n",
    "\n",
    "def generate_second_order_random_walk(graph, alias_nodes, alias_edges, \n",
    "                                      walk_length=10, start_node=None, verbose=False, max_trails=10):\n",
    "    \"\"\"\n",
    "    simulate a random walk starting from start node and considering the second order information.\n",
    "    \"\"\"\n",
    "    if start_node == None:\n",
    "        start_node = np.random.choice(graph.nodes())\n",
    "    walk = [start_node]\n",
    "    \n",
    "    prev = None\n",
    "    cur = start_node\n",
    "    num_tried = 0\n",
    "\n",
    "    ########## begin ##########\n",
    "    while len(walk) < walk_length:\n",
    "        cur_nbrs = list(graph.neighbors(cur))\n",
    "        if len(cur_nbrs) > 0:\n",
    "            if prev is None:\n",
    "                # sample the next node based on alias_nodes\n",
    "                prev, cur = cur, cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
    "            else:\n",
    "                # sample the next node based on alias_edges\n",
    "                prev, cur = cur, cur_nbrs[alias_draw(*alias_edges[(prev, cur)])]\n",
    "            walk.append(cur)\n",
    "        else:\n",
    "            num_tried += 1\n",
    "            if num_tried >= max_trails:\n",
    "                break\n",
    "            walk, (cur, prev) = fallback(walk, fetch_last_num=2)\n",
    "            if len(walk) == 0:\n",
    "                start_node = np.random.choice(graph.nodes())\n",
    "                walk = [start_node]\n",
    "                cur = start_node\n",
    "                prev = None\n",
    "    ########## end ##########\n",
    "    if verbose: \n",
    "        print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1620014647652,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "uyiQ77PQD5Xz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10):\n",
    "    \"\"\"\n",
    "    build a deepwalk model\n",
    "    \"\"\"\n",
    "    print(\"building a DeepWalk model...\", end=\"\\t\")\n",
    "    st = time.time()\n",
    "    np.random.seed(0)\n",
    "    nodes = list(graph.nodes())\n",
    "    walks = list()\n",
    "    # generate random walks\n",
    "    for walk_iter in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(generate_first_order_random_walk(\n",
    "                graph, alias_nodes, walk_length=walk_length, start_node=node))\n",
    "        \n",
    "    walk_lens = [len(w) for w in walks]\n",
    "    if len(walk_lens) > 0:\n",
    "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
    "    else:\n",
    "        avg_walk_len = 0.0\n",
    "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
    "    \n",
    "    # train a skip-gram model for these walks\n",
    "    model = Word2Vec(walks, vector_size=node_dim, window=3,alpha=5e-3, min_count=0, sg=1, workers=os.cpu_count(), epochs=50) #vector_ epochs\n",
    "    print(\"training time: %.4f\" % (time.time()-st))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10):\n",
    "    \"\"\"\n",
    "    build a node2vec model\n",
    "    \"\"\"\n",
    "    print(\"building a node2vec model...\", end=\"\\t\")\n",
    "    st = time.time()\n",
    "    np.random.seed(0)\n",
    "    nodes = list(graph.nodes())\n",
    "    walks = list()\n",
    "    # generate random walks\n",
    "    for walk_iter in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(generate_second_order_random_walk(\n",
    "                graph, alias_nodes, alias_edges, walk_length=walk_length, start_node=node))\n",
    "            \n",
    "    walk_lens = [len(w) for w in walks]\n",
    "    if len(walk_lens) > 0:\n",
    "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
    "    else:\n",
    "        avg_walk_len = 0.0    \n",
    "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
    "    \n",
    "    # train a skip-gram model for these walks\n",
    "    model = Word2Vec(walks, vector_size=node_dim, window=3, alpha=0.003, min_count=0, sg=1, workers=os.cpu_count(), epochs=60) #vector_ epochs\n",
    "    print(\"training time: %.4f\" % (time.time()-st))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1620014655891,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "myEzarAtD5aA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_cosine_sim(model, u, v):\n",
    "    \"\"\"\n",
    "    get the cosine similarity between two nodes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        u = model.wv[u]\n",
    "        v = model.wv[v]\n",
    "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "\n",
    "def get_auc_score(model, true_edges, false_edges):\n",
    "    \"\"\"\n",
    "    get the auc score\n",
    "    \"\"\"\n",
    "    y_true = [1] * len(true_edges) + [0] * len(false_edges)\n",
    "    \n",
    "    y_score = list()\n",
    "    for e in true_edges:\n",
    "        y_score.append(get_cosine_sim(model, e[0], e[1]))\n",
    "    for e in false_edges:\n",
    "        y_score.append(get_cosine_sim(model, e[0], e[1]))\n",
    "    \n",
    "    return roc_auc_score(y_true, y_score)\n",
    "\n",
    "\n",
    "def write_pred(file_name, edges, scores):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"src\"] = [e[0] for e in edges]\n",
    "    df[\"dst\"] = [e[1] for e in edges]\n",
    "    df[\"score\"] = scores\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "\n",
    "def write_valid_ans(file_name, edges, scores):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"src\"] = [e[0] for e in edges]\n",
    "    df[\"dst\"] = [e[1] for e in edges]\n",
    "    df[\"score\"] = scores\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7575,
     "status": "ok",
     "timestamp": 1620014665406,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "7pjsRr_rD6An",
    "outputId": "da92825f-3094-4799-c6e4-fc9c41060dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 8328\n",
      "number of edges: 100000\n",
      "8474 119268\n"
     ]
    }
   ],
   "source": [
    "train_file = \"/Users/cinder/Desktop/4332_project_2/train.csv\"\n",
    "valid_file = \"/Users/cinder/Desktop/4332_project_2/valid.csv\"\n",
    "test_file = \"/Users/cinder/Desktop/4332_project_2/test.csv\"\n",
    "\n",
    "np.random.seed(0)\n",
    "train_edges = load_data(train_file)\n",
    "graph = construct_graph_from_edges(train_edges)\n",
    "valid_edges = load_data(valid_file)\n",
    "false_edges = generate_false_edges(train_edges+valid_edges, 40000-len(valid_edges))\n",
    "test_edges = load_test_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 32897,
     "status": "ok",
     "timestamp": 1619957993924,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "oEEY03HLD6DU"
   },
   "outputs": [],
   "source": [
    "# alias_nodes, alias_edges = preprocess_transition_probs(graph, p=1, q=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 32894,
     "status": "ok",
     "timestamp": 1619957993924,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "lMqY3TOtD6Fw"
   },
   "outputs": [],
   "source": [
    "# # kevyen's part\n",
    "# # deep walk\n",
    "# np.random.seed(0)\n",
    "\n",
    "# node_dim = 12\n",
    "# num_walks = 26\n",
    "# walk_length = 12\n",
    "\n",
    "# deepwalk_auc_scores = dict()\n",
    "\n",
    "\n",
    "# for walk_length in [10, 12, 14]:\n",
    "#     for num_walks in [26 ,28]:\n",
    "#         print(\"node dim: %d,\\tnum_walks: %d,\\twalk_length: %d\" % (node_dim, num_walks, walk_length), end=\"\\t\")\n",
    "#         model = build_deepwalk(graph, alias_nodes, \n",
    "#                                node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "#         deepwalk_auc_scores[(node_dim, num_walks, walk_length)] = get_auc_score(model, valid_edges, false_edges)\n",
    "#         print(\"auc: %.4f\" % (deepwalk_auc_scores[(node_dim, num_walks, walk_length)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 32894,
     "status": "ok",
     "timestamp": 1619957993925,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "V3siCXstD6IT"
   },
   "outputs": [],
   "source": [
    "# # final test\n",
    "\n",
    "# for q in [16,16,16,16,16]:\n",
    "#     for p in [2,]:\n",
    "#         np.random.seed(0)\n",
    "\n",
    "#         node_dim = 12\n",
    "#         num_walks = 28\n",
    "#         walk_length = 12\n",
    "\n",
    "\n",
    "#         node2vec_auc_scores = dict()\n",
    "\n",
    "#         print(\"node dim: %d,\\tnum_walks: %d,\\twalk_length: %d,\\tp: %.2f,\\tq: %.2f\" % (\n",
    "#             node_dim, num_walks, walk_length, p, q), end=\"\\t\")\n",
    "#         alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "#         model = build_node2vec(graph, alias_nodes, alias_edges, \n",
    "#                                node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "#         node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "#         print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 32893,
     "status": "ok",
     "timestamp": 1619957993925,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "18ZGAYpcD6Ko"
   },
   "outputs": [],
   "source": [
    "# would the results be better if we change the learning rate & epoch? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1620014682606,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "P4AxJFZVD6Pz"
   },
   "outputs": [],
   "source": [
    "# modified n2v function to tune alpha\n",
    "def super_build_node2vec(alphas,graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10):\n",
    "    \"\"\"\n",
    "    build a node2vec model\n",
    "    \"\"\"\n",
    "    print(\"building a node2vec model...\", end=\"\\t\")\n",
    "    st = time.time()\n",
    "    np.random.seed(0)\n",
    "    nodes = list(graph.nodes())\n",
    "    walks = list()\n",
    "    # generate random walks\n",
    "    for walk_iter in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(generate_second_order_random_walk(\n",
    "                graph, alias_nodes, alias_edges, walk_length=walk_length, start_node=node))\n",
    "            \n",
    "    walk_lens = [len(w) for w in walks]\n",
    "    if len(walk_lens) > 0:\n",
    "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
    "    else:\n",
    "        avg_walk_len = 0.0    \n",
    "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
    "    \n",
    "    # train a skip-gram model for these walks\n",
    "    models = []\n",
    "    for alpha in alphas:\n",
    "      model = Word2Vec(walks, vector_size=node_dim, window=3, alpha=alpha, min_count=0, sg=1, workers=os.cpu_count(), epochs=50) #vector_ epochs\n",
    "      print(\"training time: %.4f\" % (time.time()-st))\n",
    "      models.append(model)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 32892,
     "status": "ok",
     "timestamp": 1619957993926,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "Xd27HxPujVvG"
   },
   "outputs": [],
   "source": [
    "# # try different alphas\n",
    "# alphas = [0.003, 0.005, 0.007]\n",
    "# node_dim = 12\n",
    "# num_walks = 28\n",
    "# walk_length = 12\n",
    "# p =2\n",
    "# q =16\n",
    "# alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "# models = super_build_node2vec(alphas, graph, alias_nodes, alias_edges, \n",
    "#                                node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "# for model in models:\n",
    "#   node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "#   print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 9235,
     "status": "error",
     "timestamp": 1620014707025,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "a9D1K0JFpSyk",
    "outputId": "5528c061-f72d-45e5-e78d-5ed5dc3f4ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a node2vec model...\tnumber of walks: 233184\taverage walk length: 11.9905\ttraining time: 98.2001\n",
      "training time: 163.5412\n",
      "training time: 226.3439\n",
      "training time: 288.8854\n",
      "training time: 348.2213\n",
      "training time: 407.2991\n"
     ]
    }
   ],
   "source": [
    "# try different alphas 2.0\n",
    "alphas = [0.0001,0.001,0.0015,0.002,0.0025,0.003]\n",
    "node_dim = 12\n",
    "num_walks = 28\n",
    "walk_length = 12\n",
    "p =2\n",
    "q =16\n",
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "models = super_build_node2vec(alphas, graph, alias_nodes, alias_edges, \n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.8481\n",
      "auc: 0.9284\n",
      "auc: 0.9337\n",
      "auc: 0.9362\n",
      "auc: 0.9371\n",
      "auc: 0.9374\n"
     ]
    }
   ],
   "source": [
    "node2vec_auc_scores = dict()\n",
    "for model in models:\n",
    "  node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "  print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2704774,
     "status": "ok",
     "timestamp": 1619964028323,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "j7FXbJLFNxTz",
    "outputId": "eabb5693-18d9-4224-8ff3-e7787326a9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a node2vec model...\tnumber of walks: 233184\taverage walk length: 11.9905\ttraining time: 423.5922\n",
      "training time: 797.7410\n",
      "training time: 1170.7936\n",
      "training time: 1543.8781\n",
      "training time: 1916.4807\n",
      "training time: 2288.1907\n",
      "training time: 2660.8208\n",
      "auc: 0.9379\n",
      "auc: 0.9385\n",
      "auc: 0.9386\n",
      "auc: 0.9385\n",
      "auc: 0.9386\n",
      "auc: 0.9387\n",
      "auc: 0.9386\n"
     ]
    }
   ],
   "source": [
    "# try different alphas 3.0\n",
    "alphas = [0.0025,0.00275,0.003,0.00325,0.0035,0.00375,0.004]\n",
    "node_dim = 12\n",
    "num_walks = 28\n",
    "walk_length = 12\n",
    "p =2\n",
    "q =16\n",
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "models = super_build_node2vec(alphas, graph, alias_nodes, alias_edges, \n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "node2vec_auc_scores = dict()\n",
    "for model in models:\n",
    "  node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "  print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1619965632526,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "l0OtekTZdyFA"
   },
   "outputs": [],
   "source": [
    "\n",
    "# modified n2v function to tune epoch\n",
    "def epoch_build_node2vec(graph, epochs,alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10):\n",
    "    \"\"\"\n",
    "    build a node2vec model\n",
    "    \"\"\"\n",
    "    print(\"building a node2vec model...\", end=\"\\t\")\n",
    "    st = time.time()\n",
    "    np.random.seed(0)\n",
    "    nodes = list(graph.nodes())\n",
    "    walks = list()\n",
    "    # generate random walks\n",
    "    for walk_iter in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(generate_second_order_random_walk(\n",
    "                graph, alias_nodes, alias_edges, walk_length=walk_length, start_node=node))\n",
    "            \n",
    "    walk_lens = [len(w) for w in walks]\n",
    "    if len(walk_lens) > 0:\n",
    "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
    "    else:\n",
    "        avg_walk_len = 0.0    \n",
    "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
    "    \n",
    "    # train a skip-gram model for these walks\n",
    "    models = []\n",
    "    for epoch in epochs:\n",
    "      model = Word2Vec(walks, vector_size=node_dim, window=3, alpha=0.003, min_count=0, sg=1, workers=os.cpu_count(), epochs=epoch) #size iter\n",
    "      print(\"training time: %.4f\" % (time.time()-st))\n",
    "      models.append(model)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1978399,
     "status": "ok",
     "timestamp": 1619972800177,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "F9E9MPoceeqB",
    "outputId": "c4bcb31a-fc19-47cf-adaf-c3ea6b703b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a node2vec model...\tnumber of walks: 233184\taverage walk length: 11.9905\ttraining time: 277.6095\n",
      "training time: 654.8307\n",
      "training time: 1188.7565\n",
      "training time: 1936.2955\n",
      "auc: 0.9353\n",
      "auc: 0.9385\n",
      "auc: 0.9391\n",
      "auc: 0.9387\n"
     ]
    }
   ],
   "source": [
    "# try different epochs 1.0\n",
    "epochs = [30,50,70,100]\n",
    "node_dim = 12\n",
    "num_walks = 28\n",
    "walk_length = 12\n",
    "p =2\n",
    "q =16\n",
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "models = epoch_build_node2vec(graph,epochs,alias_nodes, alias_edges, \n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "node2vec_auc_scores = dict()\n",
    "for model in models:\n",
    "  node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "  print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1430343,
     "status": "ok",
     "timestamp": 1619974779016,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "VZhUkl0feew9",
    "outputId": "427dbc12-9fb5-4795-fdff-833652bb5aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a node2vec model...\tnumber of walks: 233184\taverage walk length: 11.9905\ttraining time: 459.4856\n",
      "training time: 906.5237\n",
      "training time: 1388.8196\n",
      "auc: 0.9390\n",
      "auc: 0.9392\n",
      "auc: 0.9391\n"
     ]
    }
   ],
   "source": [
    "# try different epochs 2.0\n",
    "epochs = [55,60,65]\n",
    "node_dim = 12\n",
    "num_walks = 28\n",
    "walk_length = 12\n",
    "p =2\n",
    "q =16\n",
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "models = epoch_build_node2vec(graph,epochs,alias_nodes, alias_edges, \n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "node2vec_auc_scores = dict()\n",
    "for model in models:\n",
    "  node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "  print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1236947,
     "status": "ok",
     "timestamp": 1619976015976,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "BfAWxkCNee1_",
    "outputId": "bd682720-d402-4db8-ff7c-8b4f38332bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a node2vec model...\tnumber of walks: 233184\taverage walk length: 11.9905\ttraining time: 603.0525\n",
      "training time: 1196.0793\n",
      "auc: 0.9391\n",
      "auc: 0.9389\n"
     ]
    }
   ],
   "source": [
    "# try different epochs 3.0\n",
    "epochs = [75,80]\n",
    "node_dim = 12\n",
    "num_walks = 28\n",
    "walk_length = 12\n",
    "p =2\n",
    "q =16\n",
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "models = epoch_build_node2vec(graph,epochs,alias_nodes, alias_edges, \n",
    "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "node2vec_auc_scores = dict()\n",
    "for model in models:\n",
    "  node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "  print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537146,
     "status": "ok",
     "timestamp": 1619978385109,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "VTtysdnAee-P",
    "outputId": "d5918b26-18ea-4b2b-f9f9-dfd90ff36977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node dim: 12,\tnum_walks: 28,\twalk_length: 12,\tp: 2.00,\tq: 16.00\tlearning rate: 0.003\tepoch: 60\tbuilding a node2vec model...\tnumber of walks: 233184\taverage walk length: 11.9905\ttraining time: 495.2393\n",
      "auc: 0.9391\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "node_dim = 12\n",
    "num_walks = 28\n",
    "walk_length = 12\n",
    "p =2\n",
    "q =16\n",
    "\n",
    "node2vec_auc_scores = dict()\n",
    "\n",
    "print(\"node dim: %d,\\tnum_walks: %d,\\twalk_length: %d,\\tp: %.2f,\\tq: %.2f\\tlearning rate: 0.003\\tepoch: 60\" % (\n",
    "    node_dim, num_walks, walk_length, p, q), end=\"\\t\")\n",
    "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
    "model = build_node2vec(graph, alias_nodes, alias_edges, \n",
    "                        node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
    "node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
    "print(\"auc: %.4f\" % (node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1638,
     "status": "ok",
     "timestamp": 1619978552633,
     "user": {
      "displayName": "陈子昕",
      "photoUrl": "",
      "userId": "04617232744031557406"
     },
     "user_tz": -480
    },
    "id": "PMDRBhCfM14P"
   },
   "outputs": [],
   "source": [
    "# prediction with best model\n",
    "scores = [get_cosine_sim(model, src, dst) for src, dst in test_edges]\n",
    "write_pred(\"/Users/cinder/Desktop/4332_project_2/pred.csv\", test_edges, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8XAclTsRooK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+0r8NJ4cyLBiQtwV21nnT",
   "collapsed_sections": [],
   "name": "PA2_trials.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
